import os
import json
import logging
import asyncio
import websockets
from flask import Flask, render_template, request, jsonify
from flask_sock import Sock
from flask_cors import CORS
import google.generativeai as genai
from google.cloud import storage
import datetime

app = Flask(__name__)
CORS(app)
sock = Sock(app)
logging.basicConfig(level=logging.INFO)

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
MODEL_NAME = "models/gemini-2.0-flash-exp"
GCS_BUCKET_NAME = os.getenv("GCS_BUCKET_NAME")



@app.route('/')
def index():
    return render_template('index.html')

# WebSocketãƒ—ãƒ­ã‚­ã‚·ï¼ˆå¤‰æ›´ãªã—ï¼‰
@sock.route('/ws/realtime')
def realtime_proxy(ws_client):
    host = "generativelanguage.googleapis.com"
    url = f"wss://{host}/ws/google.ai.generativelanguage.v1alpha.GenerativeService.BidiGenerateContent?key={GEMINI_API_KEY}"
    setup_msg = {
        "setup": {
            "model": MODEL_NAME,
            "system_instruction": { "parts": [{"text": "ã‚ãªãŸã¯ITä¼æ¥­ã®å°å…¥æ‹…å½“è€…ï¼ˆé¡§å®¢ï¼‰ã§ã™...ï¼ˆç•¥ï¼‰"}] },
            "generation_config": {
                "response_modalities": ["AUDIO"],
                "speech_config": { "voice_config": {"prebuilt_voice_config": {"voice_name": "Aoede"}} }
            }
        }
    }
    # ... (ãƒ—ãƒ­ã‚­ã‚·å‡¦ç†ã¯å‰å›ã¨åŒã˜ãªã®ã§çœç•¥å¯ã€ãã®ã¾ã¾ã§OK) ...
    async def proxy_handler():
        try:
            async with websockets.connect(url) as ws_gemini:
                await ws_gemini.send(json.dumps(setup_msg))
                async def forward_to_gemini():
                    while True:
                        try:
                            data = await asyncio.to_thread(ws_client.receive)
                            if data is None: break
                            await ws_gemini.send(data)
                        except: break
                async def forward_to_client():
                    async for msg in ws_gemini:
                        try:
                            if isinstance(msg, bytes): msg = msg.decode('utf-8')
                            ws_client.send(msg)
                        except: break
                await asyncio.gather(forward_to_gemini(), forward_to_client())
        except: pass
    try: asyncio.run(proxy_handler())
    except: pass


# ---------------------------------------------------------
# ğŸ“ è©•ä¾¡ (ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å—ã‘å–ã‚‹ã‚ˆã†ã«å¤‰æ›´)
# ---------------------------------------------------------
@app.route('/feedback', methods=['POST'])
def feedback():
    try:
        # FormDataã‹ã‚‰å–å¾—
        conversation_log = request.form.get('log', '')
        audio_file = request.files.get('audio')

        # éŸ³å£°ã‚’ä¸€æ™‚ä¿å­˜
        audio_path = "temp_ai_response.wav"
        if audio_file:
            audio_file.save(audio_path)
            logging.info("Audio file received.")

        if conversation_log and GCS_BUCKET_NAME:
            try:
                timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
                log_filename = f"logs/log_users/log_{timestamp}.txt"
                
                storage_client = storage.Client()
                bucket = storage_client.bucket(GCS_BUCKET_NAME)
                blob = bucket.blob(log_filename)
                
                blob.upload_from_string(conversation_log, content_type='text/plain')
                logging.info(f"Conversation log uploaded to gs://{GCS_BUCKET_NAME}/{log_filename}")
            except Exception as e:
                logging.error(f"Failed to upload log to GCS: {e}")

        # Gemini 1.5 Flash (ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¯¾å¿œ)
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel('gemini-flash-latest')

        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        uploaded_audio = None
        if os.path.exists(audio_path):
           uploaded_audio = genai.upload_file(audio_path, mime_type="audio/wav")

        prompt = f"""
        ã‚ãªãŸã¯å–¶æ¥­ç ”ä¿®ã®ã‚³ãƒ¼ãƒã§ã™ã€‚  
        
        ã€è³‡æ–™1ã€‘ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼ˆå–¶æ¥­æ‹…å½“ï¼‰ã®ç™ºè¨€ãƒ­ã‚°:
        {conversation_log}

        ã€è³‡æ–™2ã€‘AIé¡§å®¢ã®ç™ºè¨€éŸ³å£°:
        (æ·»ä»˜ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«)

        ã€æŒ‡ç¤ºã€‘
        1. ã¾ãšã€æ·»ä»˜ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆAIé¡§å®¢ã®ç™ºè¨€ï¼‰ã‚’èãå–ã‚Šã€å†…å®¹ã‚’æ–‡å­—èµ·ã“ã—ã—ã¦ãã ã•ã„ã€‚
        2. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ãƒ­ã‚°ã¨åˆã‚ã›ã¦ã€ä¼šè©±å…¨ä½“ã®æµã‚Œã‚’å†ç¾ã—ã¦ãã ã•ã„ã€‚
        3. ãã®ä¼šè©±å…¨ä½“ã«åŸºã¥ã„ã¦ã€å–¶æ¥­æ‹…å½“è€…ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

        ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
        ## ä¼šè©±ã®å†ç¾ï¼ˆè¦ç´„ï¼‰
        - å–¶æ¥­: ...
        - é¡§å®¢: ...

        ## ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
        1. **è‰¯ã‹ã£ãŸç‚¹**
        2. **æ”¹å–„ç‚¹**
        3. **ç·åˆã‚¹ã‚³ã‚¢** (/100)
        """

        contents = [prompt]
        if uploaded_audio:
            contents.append(uploaded_audio)

        response = model.generate_content(contents)
        
        # å¾Œå§‹æœ«
        if os.path.exists(audio_path):
            os.remove(audio_path)

        return jsonify({"feedback": response.text})

    except Exception as e:
        logging.error(f"Feedback Error: {e}")
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=True)