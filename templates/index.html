<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <title>AIå–¶æ¥­ãƒ­ãƒ¼ãƒ—ãƒ¬ Live (Smooth Audio)</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <style>
        .listening { animation: pulse 1.5s infinite; border: 2px solid #198754; }
        @keyframes pulse { 0% { box-shadow: 0 0 0 0 rgba(25, 135, 84, 0.7); } 70% { box-shadow: 0 0 0 10px rgba(25, 135, 84, 0); } 100% { box-shadow: 0 0 0 0 rgba(25, 135, 84, 0); } }
        #chat-area { height: 400px; overflow-y: auto; background: #f8f9fa; border: 1px solid #ddd; padding: 15px; border-radius: 5px; }
        .msg-user { text-align: right; color: #0d6efd; margin: 5px; font-weight: bold; }
        .msg-ai { text-align: left; color: #198754; margin: 5px; font-weight: bold; }
    </style>
</head>
<body class="bg-light">

<div class="container py-5">
    <h2 class="text-center mb-4">ğŸ“ AIé¡§å®¢ã¨ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å•†è«‡</h2>
    
    <div class="row justify-content-center">
        <div class="col-md-8">
            <div class="card shadow-sm mb-4">
                <div class="card-body text-center">
                    <p class="text-muted">ãƒã‚¤ã‚¯ã‚’ONã«ã—ã¦è©±ã—ã‹ã‘ã¦ãã ã•ã„</p>
                    <button id="connectBtn" class="btn btn-primary btn-lg rounded-pill px-5">
                        å•†è«‡é–‹å§‹ï¼ˆæ¥ç¶šï¼‰
                    </button>
                    <button id="disconnectBtn" class="btn btn-danger btn-lg rounded-pill px-5 d-none">
                        å•†è«‡çµ‚äº†
                    </button>
                    <div id="status" class="mt-3 badge bg-secondary">å¾…æ©Ÿä¸­</div>
                </div>
            </div>

            <div class="card shadow-sm mb-4">
                <div class="card-header">ä¼šè©±ãƒ­ã‚°</div>
                <div id="chat-area"></div>
            </div>

            <div class="card shadow-sm">
                <div class="card-header bg-dark text-white">ä¸Šå¸ã‹ã‚‰ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯</div>
                <div class="card-body">
                    <div id="feedbackContent">å•†è«‡çµ‚äº†å¾Œã«è©•ä¾¡ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚</div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    let socket;
    let audioContext;
    let processor;
    let inputSource;
    let conversationLog = []; 
    let recognition;
    
    // â˜…è¿½åŠ : éŸ³å£°ã‚’æ»‘ã‚‰ã‹ã«ã¤ãªããŸã‚ã®äºˆç´„æ™‚é–“ç®¡ç†
    let nextStartTime = 0;

    const connectBtn = document.getElementById('connectBtn');
    const disconnectBtn = document.getElementById('disconnectBtn');
    const status = document.getElementById('status');
    const chatArea = document.getElementById('chat-area');

    // â–¼ éŸ³å£°èªè­˜ (è¡¨ç¤ºç”¨)
    function setupSpeechRecognition() {
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        if (!SpeechRecognition) return null;
        const rec = new SpeechRecognition();
        rec.lang = 'ja-JP';
        rec.continuous = true;
        rec.interimResults = false;
        rec.onresult = (event) => {
            const last = event.results.length - 1;
            const text = event.results[last][0].transcript;
            if (text.trim() !== "") addLog("User", text);
        };
        return rec;
    }

    // â–¼ ãƒ‡ãƒ¼ã‚¿å¤‰æ›ç³»
    function arrayBufferToBase64(buffer) {
        let binary = '';
        const bytes = new Uint8Array(buffer);
        for (let i = 0; i < bytes.byteLength; i++) binary += String.fromCharCode(bytes[i]);
        return window.btoa(binary);
    }

    function floatTo16BitPCM(input) {
        const output = new Int16Array(input.length);
        for (let i = 0; i < input.length; i++) {
            const s = Math.max(-1, Math.min(1, input[i]));
            output[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
        }
        return output.buffer;
    }

    // â–  æ¥ç¶šé–‹å§‹
    connectBtn.addEventListener('click', async () => {
        try {
            status.textContent = "æ¥ç¶šä¸­...";
            
            // AudioContextåˆæœŸåŒ– (ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆæŒ‡å®šã¯ãƒ–ãƒ©ã‚¦ã‚¶ã«ã‚ˆã£ã¦ç„¡è¦–ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚‹ãŒæŒ‡å®šã—ã¦ãŠã)
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
            } else if (audioContext.state === 'suspended') {
                await audioContext.resume();
            }
            
            // å†ç”Ÿæ™‚é–“ã‚’ãƒªã‚»ãƒƒãƒˆ
            nextStartTime = audioContext.currentTime;

            // WebSocketæ¥ç¶š
            const protocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
            socket = new WebSocket(`${protocol}//${location.host}/ws/realtime`);

            socket.onopen = async () => {
                status.textContent = "é€šè©±ä¸­";
                status.className = "mt-3 badge bg-success listening";
                connectBtn.classList.add('d-none');
                disconnectBtn.classList.remove('d-none');
                
                await startMicrophone();
                recognition = setupSpeechRecognition();
                if(recognition) recognition.start();
            };

            // å—ä¿¡å‡¦ç†
            socket.onmessage = async (event) => {
                try {
                    let textData;
                    if (event.data instanceof Blob) {
                        textData = await event.data.text();
                    } else {
                        textData = event.data;
                    }
                    const response = JSON.parse(textData);
                    
                    if (response.serverContent?.modelTurn?.parts) {
                        for (const part of response.serverContent.modelTurn.parts) {
                            if (part.inlineData && part.inlineData.mimeType.startsWith('audio')) {
                                const audioStr = atob(part.inlineData.data);
                                playAudio(audioStr);
                            }
                            if (part.text) {
                                addLog("AI", part.text);
                            }
                        }
                    }
                } catch (e) {
                    console.error("å—ä¿¡ã‚¨ãƒ©ãƒ¼:", e);
                }
            };

            socket.onclose = () => stopAll();
            socket.onerror = (e) => {
                alert("æ¥ç¶šã‚¨ãƒ©ãƒ¼");
                stopAll();
            };

        } catch (e) {
            alert("ã‚¨ãƒ©ãƒ¼: " + e.message);
        }
    });

    // â–  åˆ‡æ–­ï¼†è©•ä¾¡
    disconnectBtn.addEventListener('click', async () => {
        stopAll();
        status.textContent = "è©•ä¾¡ä½œæˆä¸­...";
        status.className = "mt-3 badge bg-warning text-dark";
        
        const logText = conversationLog.map(l => `${l.role}: ${l.text}`).join("\n");
        try {
            const res = await fetch('/feedback', {
                method: 'POST',
                headers: {'Content-Type': 'application/json'},
                body: JSON.stringify({ log: logText || "ï¼ˆéŸ³å£°ã®ã¿ã®å¯¾è©±ã§ã—ãŸï¼‰" })
            });
            const data = await res.json();
            document.getElementById('feedbackContent').innerHTML = marked.parse(data.feedback);
            status.textContent = "å®Œäº†";
            status.className = "mt-3 badge bg-secondary";
        } catch(e) {
            status.textContent = "è©•ä¾¡ã‚¨ãƒ©ãƒ¼";
        }
    });

    function stopAll() {
        if(socket) socket.close();
        stopMicrophone();
        if(recognition) recognition.stop();
        connectBtn.classList.remove('d-none');
        disconnectBtn.classList.add('d-none');
        status.textContent = "å¾…æ©Ÿä¸­";
        status.className = "mt-3 badge bg-secondary";
    }

    // â–  ãƒã‚¤ã‚¯å…¥åŠ›
    async function startMicrophone() {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: { channelCount: 1, sampleRate: 24000 } });
        inputSource = audioContext.createMediaStreamSource(stream);
        processor = audioContext.createScriptProcessor(4096, 1, 1);
        
        inputSource.connect(processor);
        processor.connect(audioContext.destination);

        processor.onaudioprocess = (e) => {
            if (!socket || socket.readyState !== WebSocket.OPEN) return;
            const inputData = e.inputBuffer.getChannelData(0);
            
            // â˜…é‡è¦: å˜ç´”ãªé–“å¼•ãï¼ˆãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰ã¯éŸ³è³ªåŠ£åŒ–ã®åŸå› ã«ãªã‚‹ãŸã‚ã€
            // ä»Šå›ã¯ãƒ–ãƒ©ã‚¦ã‚¶ã®ãƒ¬ãƒ¼ãƒˆã®ã¾ã¾é€ä¿¡ã—ã€ã‚µãƒ¼ãƒãƒ¼å´(Gemini)ã®è¨±å®¹ç¯„å›²ã«ä»»ã›ã‚‹ã€‚
            // (24kæŒ‡å®šã—ã¦ã‚‚48kã«ãªã‚‹ç’°å¢ƒãŒå¤šã„ãŒã€Geminiã¯æ¯”è¼ƒçš„æŸ”è»Ÿã«å¯¾å¿œã™ã‚‹)
            
            const pcmData = floatTo16BitPCM(inputData);
            const base64Audio = arrayBufferToBase64(pcmData);

            socket.send(JSON.stringify({
                realtime_input: {
                    media_chunks: [{
                        mime_type: "audio/pcm",
                        data: base64Audio
                    }]
                }
            }));
        };
    }

    function stopMicrophone() {
        if (inputSource) inputSource.disconnect();
        if (processor) processor.disconnect();
    }

    // â–  éŸ³å£°å†ç”Ÿ (ã‚­ãƒ¥ãƒ¼ã‚¤ãƒ³ã‚°å®Ÿè£…ç‰ˆ)
    async function playAudio(base64String) {
        if (!base64String || base64String.length === 0) return;

        // Base64 -> Byteå¤‰æ›
        const audioData = new Uint8Array(base64String.length);
        for(let i=0; i<base64String.length; i++) audioData[i] = base64String.charCodeAt(i);
        
        if (!audioContext) return;
        const pcm16 = new Int16Array(audioData.buffer);
        if (pcm16.length === 0) return;

        const float32 = new Float32Array(pcm16.length);
        for(let i=0; i<pcm16.length; i++) float32[i] = pcm16[i] / 32768;

        // 24kHzã§ãƒãƒƒãƒ•ã‚¡ä½œæˆ (Geminiã®å‡ºåŠ›ã¯é€šå¸¸24kHz)
        const buffer = audioContext.createBuffer(1, float32.length, 24000);
        buffer.getChannelData(0).set(float32);

        const source = audioContext.createBufferSource();
        source.buffer = buffer;
        source.connect(audioContext.destination);

        // â˜…â˜…â˜… ã“ã“ãŒä¿®æ­£ã®è‚ â˜…â˜…â˜…
        // æ¬¡ã®å†ç”Ÿé–‹å§‹æ™‚é–“ãŒã€ç¾åœ¨æ™‚åˆ»ã‚ˆã‚Šéå»ã«ãªã£ã¦ã„ãŸã‚‰ã€ç¾åœ¨æ™‚åˆ»ã«ãƒªã‚»ãƒƒãƒˆ
        // (ã¤ã¾ã‚Šã€é…å»¶ã—ã¦ãªã„ãªã‚‰äºˆç´„æ™‚åˆ»ã«ã€é…å»¶ã—ã¦ãŸã‚‰å³å†ç”Ÿ)
        if (nextStartTime < audioContext.currentTime) {
            nextStartTime = audioContext.currentTime;
        }
        
        source.start(nextStartTime);
        
        // æ¬¡ã®éŸ³å£°ã®é–‹å§‹æ™‚é–“ã‚’æ›´æ–° (ä»Šã®éŸ³å£°ã®é•·ã•åˆ†ã ã‘å¾Œã‚ã«ãšã‚‰ã™)
        nextStartTime += buffer.duration;
    }

    function addLog(role, text) {
        const div = document.createElement('div');
        div.className = role === "User" ? "msg-user" : "msg-ai";
        div.textContent = text;
        chatArea.appendChild(div);
        chatArea.scrollTop = chatArea.scrollHeight;
        conversationLog.push({role, text});
    }
</script>
</body>
</html>